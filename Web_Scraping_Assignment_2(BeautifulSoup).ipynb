{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244e751a",
   "metadata": {},
   "source": [
    "# Web Scraping - Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6e56a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1c5aa",
   "metadata": {},
   "source": [
    "QUESTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ed4aa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From today's featured list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Headers\n",
       "0  From today's featured article\n",
       "1               Did you know ...\n",
       "2                    In the news\n",
       "3                    On this day\n",
       "4     From today's featured list\n",
       "5       Today's featured picture\n",
       "6       Other areas of Wikipedia\n",
       "7    Wikipedia's sister projects\n",
       "8            Wikipedia languages"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Write a python program to display all the header tags from wikipedia.org and make data frame.\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#Sending get request to the webpage server to get the source code of the page\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "\n",
    "#Page content\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#Scraping header tags\n",
    "headers = []\n",
    "for i in soup.find_all('h2',class_=\"mp-h2\"):\n",
    "    headers.append(i.text)\n",
    "headers\n",
    "\n",
    "#Making Dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Headers':headers})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4aef04",
   "metadata": {},
   "source": [
    "QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38fd0c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Former Presidents of India</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind 14th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee 13th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil 12th President o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam 11th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan 10th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma 9th  President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman 8th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh 7th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy 6th President of In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed 5th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri 4th President of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain 3rd President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan 2nd President of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad 1st President of India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Former Presidents of India\n",
       "0       Shri Ram Nath Kovind 14th President of India \n",
       "1      Shri Pranab Mukherjee 13th President of India \n",
       "2    Smt Pratibha Devisingh Patil 12th President o...\n",
       "3     DR. A.P.J. Abdul Kalam 11th President of India \n",
       "4       Shri K. R. Narayanan 10th President of India \n",
       "5    Dr Shankar Dayal Sharma 9th  President of India \n",
       "6         Shri R Venkataraman 8th President of India \n",
       "7            Giani Zail Singh 7th President of India \n",
       "8    Shri Neelam Sanjiva Reddy 6th President of In...\n",
       "9    Dr. Fakhruddin Ali Ahmed 5th President of India \n",
       "10   Shri Varahagiri Venkata Giri 4th President of...\n",
       "11           Dr. Zakir Husain 3rd President of India \n",
       "12   Dr. Sarvepalli Radhakrishnan 2nd President of...\n",
       "13        Dr. Rajendra Prasad 1st President of India "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm and make data frame.'''\n",
    "\n",
    "#Sending get request to the webpage server to get the source code of the page\n",
    "page1 = requests.get('https://presidentofindia.nic.in/former-presidents')\n",
    "page1\n",
    "\n",
    "#Page content\n",
    "soup1 = BeautifulSoup(page1.content)\n",
    "soup1\n",
    "\n",
    "first = soup1.find('div',class_=\"desc-sec\")\n",
    "\n",
    "#Scraping header tags\n",
    "presidents = []\n",
    "for i in soup1.find_all('div',class_=\"desc-sec\"):\n",
    "    presidents.append(i.text.replace('\\n',' '))\n",
    "\n",
    "presidents\n",
    "\n",
    "#Making Dataframe\n",
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'Former Presidents of India':presidents})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c03ec",
   "metadata": {},
   "source": [
    "QUESTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7fca3687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>49</td>\n",
       "      <td>5,839</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>36</td>\n",
       "      <td>4,015</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>32</td>\n",
       "      <td>3,525</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>29</td>\n",
       "      <td>3,166</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>38</td>\n",
       "      <td>4,007</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>England</td>\n",
       "      <td>34</td>\n",
       "      <td>3,377</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>43</td>\n",
       "      <td>3,943</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>40</td>\n",
       "      <td>3,574</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>26</td>\n",
       "      <td>2,170</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>38</td>\n",
       "      <td>2,582</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches Points Ratings\n",
       "0         India      49  5,839     118\n",
       "1     Australia      36  4,015     112\n",
       "2      Pakistan      32  3,525     110\n",
       "3  South Africa      29  3,166     109\n",
       "4   New Zealand      38  4,007     105\n",
       "5       England      34  3,377      99\n",
       "6     Sri Lanka      43  3,943      92\n",
       "7    Bangladesh      40  3,574      89\n",
       "8   Afghanistan      26  2,170      83\n",
       "9   West Indies      38  2,582      68"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame.\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating.'''\n",
    "\n",
    "#a) Top 10 ODI teams in men's cricket along with the records for matches, points and rating.\n",
    "page2 = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page2\n",
    "\n",
    "#Page content\n",
    "soup2 = BeautifulSoup(page2.content)\n",
    "soup2\n",
    " \n",
    "first2 = soup2.find('td',class_=\"rankings-block__banner--matches\")\n",
    "b = first2.text\n",
    "first3 = soup2.find('td',class_=\"rankings-block__banner--points\")\n",
    "c = first3.text\n",
    "actual_ratings = ['118']\n",
    "matches_points = [b,c]\n",
    "\n",
    "teams = []\n",
    "for i in soup2.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    teams.append(i.text)\n",
    "t = teams[:10]\n",
    "t\n",
    "\n",
    "matches = []\n",
    "for i in soup2.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    matches.append(i.text)\n",
    "matches\n",
    "matches_points.extend(matches)\n",
    "matches_and_points = matches_points\n",
    "matches1 = matches_points[0:39:2]\n",
    "points1 = matches_points[1:39:2]\n",
    "m1 = matches1[:10]\n",
    "p1 = points1[:10]\n",
    "\n",
    "ratings = []\n",
    "for i in soup2.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    ratings.append(i.text)\n",
    "ratings\n",
    "actual_ratings.extend(ratings)\n",
    "actual_ratings1 = actual_ratings\n",
    "a_r1 = actual_ratings1[:10]\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Teams':t,'Matches':m1,'Points':p1,'Ratings':a_r1})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "faf22310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsmens</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>829</td>\n",
       "      <td>898vWestIndies,10/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>823</td>\n",
       "      <td>847vAustralia,24/09/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>769</td>\n",
       "      <td>813vSriLanka,10/03/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heinrich Klaasen</td>\n",
       "      <td>756</td>\n",
       "      <td>756vBangladesh,24/10/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>747</td>\n",
       "      <td>880vPakistan,26/01/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>747</td>\n",
       "      <td>911vEngland,12/07/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>729</td>\n",
       "      <td>729vEngland,23/09/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>725</td>\n",
       "      <td>885vSriLanka,06/07/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>716</td>\n",
       "      <td>796vEngland,19/07/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>704</td>\n",
       "      <td>815vWestIndies,12/06/2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Batsmens Ratings                    Records\n",
       "0             Babar Azam     829  898vWestIndies,10/06/2022\n",
       "1           Shubman Gill     823   847vAustralia,24/09/2023\n",
       "2        Quinton de Kock     769    813vSriLanka,10/03/2019\n",
       "3       Heinrich Klaasen     756  756vBangladesh,24/10/2023\n",
       "4           David Warner     747    880vPakistan,26/01/2017\n",
       "5            Virat Kohli     747     911vEngland,12/07/2018\n",
       "6           Harry Tector     729     729vEngland,23/09/2023\n",
       "7           Rohit Sharma     725    885vSriLanka,06/07/2019\n",
       "8  Rassie van der Dussen     716     796vEngland,19/07/2022\n",
       "9            Imam-ul-Haq     704  815vWestIndies,12/06/2022"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "page3 = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "\n",
    "soup3 = BeautifulSoup(page3.content)\n",
    "\n",
    "batsmen = []\n",
    "for i in soup3.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    batsmen.append(i.text.replace('\\n',''))\n",
    "batsmen.insert(0,'Babar Azam')\n",
    "b = batsmen[:10]\n",
    "\n",
    "\n",
    "rating = []\n",
    "for i in soup3.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text)\n",
    "rating.insert(0,'829')\n",
    "r= rating[:10]\n",
    "\n",
    "\n",
    "record = []\n",
    "for i in soup3.find_all('td',class_=\"table-body__cell u-text-right u-hide-phablet\"):\n",
    "    record.append(i.text.replace(' ','').replace('\\n',''))\n",
    "record.insert(0,'898vWestIndies,10/06/2022')\n",
    "re = record[:10]\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Batsmens':b,'Ratings':r,'Records':re})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f278e5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowlers</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>670</td>\n",
       "      <td>733vEngland,26/01/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>668</td>\n",
       "      <td>736vNewZealand,21/01/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keshav Maharaj</td>\n",
       "      <td>656</td>\n",
       "      <td>656vBangladesh,24/10/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>654</td>\n",
       "      <td>806vPakistan,21/09/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>653</td>\n",
       "      <td>775vAustralia,11/09/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>641</td>\n",
       "      <td>657vZimbabwe,09/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>635</td>\n",
       "      <td>670vSouthAfrica,09/09/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>634</td>\n",
       "      <td>691vBangladesh,26/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kuldeep Yadav</td>\n",
       "      <td>632</td>\n",
       "      <td>765vNewZealand,26/01/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>625</td>\n",
       "      <td>688vWestIndies,10/06/2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Bowlers Ratings                     Records\n",
       "0  Josh Hazlewood     670      733vEngland,26/01/2018\n",
       "1  Mohammed Siraj     668   736vNewZealand,21/01/2023\n",
       "2  Keshav Maharaj     656   656vBangladesh,24/10/2023\n",
       "3     Rashid Khan     654     806vPakistan,21/09/2018\n",
       "4     Trent Boult     653    775vAustralia,11/09/2022\n",
       "5   Mohammad Nabi     641     657vZimbabwe,09/06/2022\n",
       "6      Adam Zampa     635  670vSouthAfrica,09/09/2023\n",
       "7      Matt Henry     634   691vBangladesh,26/03/2021\n",
       "8   Kuldeep Yadav     632   765vNewZealand,26/01/2019\n",
       "9  Shaheen Afridi     625   688vWestIndies,10/06/2022"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c)Top 10 ODI bowlers along with the records of their team and rating.\n",
    "page4 = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "\n",
    "soup4 = BeautifulSoup(page4.content)\n",
    "\n",
    "bowlers = []\n",
    "for i in soup4.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    bowlers.append(i.text.replace('\\n',''))\n",
    "bowlers\n",
    "bowlers.insert(0,'Josh Hazlewood')\n",
    "bo = bowlers[:10]\n",
    "\n",
    "rating = []\n",
    "for i in soup4.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text)\n",
    "rating\n",
    "rating.insert(0,'670')\n",
    "r= rating[:10]\n",
    "\n",
    "record = []\n",
    "for i in soup4.find_all('td',class_=\"table-body__cell u-text-right u-hide-phablet\"):\n",
    "    record.append(i.text.replace(' ','').replace('\\n',''))\n",
    "record\n",
    "record.insert(0,'733vEngland,26/01/2018')\n",
    "re = record[:10]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Bowlers':bo,'Ratings':r,'Records':re})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8da7bb",
   "metadata": {},
   "source": [
    "QUESTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5e5c8c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>19</td>\n",
       "      <td>3,084</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>23</td>\n",
       "      <td>2,991</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>21</td>\n",
       "      <td>2,446</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>18</td>\n",
       "      <td>1,745</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>2,014</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>18</td>\n",
       "      <td>1,610</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>9</td>\n",
       "      <td>714</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>11</td>\n",
       "      <td>816</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>11</td>\n",
       "      <td>753</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>21</td>\n",
       "      <td>1,435</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches Points Ratings\n",
       "0     Australia      19  3,084     162\n",
       "1       England      23  2,991     130\n",
       "2  South Africa      21  2,446     116\n",
       "3         India      18  1,745      97\n",
       "4   New Zealand      21  2,014      96\n",
       "5   West Indies      18  1,610      89\n",
       "6     Sri Lanka       9    714      79\n",
       "7    Bangladesh      11    816      74\n",
       "8      Thailand      11    753      68\n",
       "9      Pakistan      21  1,435      68"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame.\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating.'''\n",
    "\n",
    "#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "\n",
    "#Page content\n",
    "soup1 = BeautifulSoup(page.content)\n",
    " \n",
    "teams = []\n",
    "for i in soup1.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    teams.append(i.text)\n",
    "teams\n",
    "te = teams[:10]\n",
    "\n",
    "\n",
    "matches_points = []\n",
    "for i in soup1.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    matches_points.append(i.text)\n",
    "matches_points.insert(0,'19')\n",
    "matches_points.insert(1,'3,084')\n",
    "m_p = matches_points\n",
    "m1 = m_p[0:26:2]\n",
    "p1 = m_p[1:26:2]\n",
    "m2 = m1[:10]\n",
    "p2 = p1[:10]\n",
    "\n",
    "ratings = []\n",
    "for i in soup1.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    ratings.append(i.text)\n",
    "ratings.insert(0,'162')\n",
    "r = ratings[:10]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Teams':te,'Matches':m2,'Points':p2,'Ratings':r})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5edf6240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Female Batsmen</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>807</td>\n",
       "      <td>807vSriLanka,14/09/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>750</td>\n",
       "      <td>776vEngland,12/07/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>736</td>\n",
       "      <td>758vNewZealand,03/07/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>727</td>\n",
       "      <td>741vAustralia,22/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>708</td>\n",
       "      <td>797vEngland,28/02/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>698</td>\n",
       "      <td>785vEngland,03/04/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>697</td>\n",
       "      <td>766vWestIndies,11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>694</td>\n",
       "      <td>731vEngland,21/09/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>662</td>\n",
       "      <td>834vNewZealand,24/02/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>642</td>\n",
       "      <td>642vNewZealand,01/10/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Female Batsmen Ratings                    Records\n",
       "0  Natalie Sciver-Brunt     807    807vSriLanka,14/09/2023\n",
       "1           Beth Mooney     750     776vEngland,12/07/2023\n",
       "2   Chamari Athapaththu     736  758vNewZealand,03/07/2023\n",
       "3       Laura Wolvaardt     727   741vAustralia,22/03/2022\n",
       "4       Smriti Mandhana     708     797vEngland,28/02/2019\n",
       "5          Alyssa Healy     698     785vEngland,03/04/2022\n",
       "6          Ellyse Perry     697  766vWestIndies,11/09/2019\n",
       "7      Harmanpreet Kaur     694     731vEngland,21/09/2022\n",
       "8           Meg Lanning     662  834vNewZealand,24/02/2016\n",
       "9        Marizanne Kapp     642  642vNewZealand,01/10/2023"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b)Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "page1 = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "\n",
    "soup2 = BeautifulSoup(page1.content)\n",
    "\n",
    "w_batsmen = []\n",
    "for i in soup2.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    w_batsmen.append(i.text.replace('\\n',''))\n",
    "w_batsmen\n",
    "w_batsmen.insert(0,'Natalie Sciver-Brunt')\n",
    "w_b = w_batsmen[:10]\n",
    "\n",
    "rating = []\n",
    "for i in soup2.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text)\n",
    "rating\n",
    "rating.insert(0,'807')\n",
    "r= rating[:10]\n",
    "\n",
    "record = []\n",
    "for i in soup2.find_all('td',class_=\"table-body__cell u-text-right u-hide-phablet\"):\n",
    "    record.append(i.text.replace(' ','').replace('\\n',''))\n",
    "record\n",
    "record.insert(0,'807vSriLanka,14/09/2023')\n",
    "re = record[:10]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Female Batsmen':w_b,'Ratings':r,'Records':re})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f805d498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Female All-Rounder</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>385</td>\n",
       "      <td>419vWestIndies,10/09/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>377</td>\n",
       "      <td>391vWestIndies,08/10/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>360</td>\n",
       "      <td>421vAustralia,18/07/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>358</td>\n",
       "      <td>392vIreland,26/06/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>346</td>\n",
       "      <td>356vWestIndies,25/09/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>312</td>\n",
       "      <td>397vSouthAfrica,09/10/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>282</td>\n",
       "      <td>548vWestIndies,11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>227</td>\n",
       "      <td>308vWestIndies,11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>227</td>\n",
       "      <td>305vAustralia,05/10/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>224</td>\n",
       "      <td>232vAustralia,21/01/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Female All-Rounder Ratings                     Records\n",
       "0        Marizanne Kapp     385   419vWestIndies,10/09/2021\n",
       "1      Ashleigh Gardner     377   391vWestIndies,08/10/2023\n",
       "2  Natalie Sciver-Brunt     360    421vAustralia,18/07/2023\n",
       "3       Hayley Matthews     358      392vIreland,26/06/2023\n",
       "4           Amelia Kerr     346   356vWestIndies,25/09/2022\n",
       "5         Deepti Sharma     312  397vSouthAfrica,09/10/2019\n",
       "6          Ellyse Perry     282   548vWestIndies,11/09/2019\n",
       "7         Jess Jonassen     227   308vWestIndies,11/09/2019\n",
       "8         Sophie Devine     227    305vAustralia,05/10/2020\n",
       "9              Nida Dar     224    232vAustralia,21/01/2023"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "page2 = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "\n",
    "soup3 = BeautifulSoup(page2.content)\n",
    "\n",
    "w_all_rounder = []\n",
    "for i in soup3.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    w_all_rounder.append(i.text.replace('\\n',''))\n",
    "w_all_rounder\n",
    "w_all_rounder.insert(0,'Marizanne Kapp')\n",
    "w_ar = w_all_rounder[:10]\n",
    "\n",
    "rating = []\n",
    "for i in soup3.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text)\n",
    "rating\n",
    "rating.insert(0,'385')\n",
    "r= rating[:10]\n",
    "\n",
    "record = []\n",
    "for i in soup3.find_all('td',class_=\"table-body__cell u-text-right u-hide-phablet\"):\n",
    "    record.append(i.text.replace(' ','').replace('\\n',''))\n",
    "record\n",
    "record.insert(0,'419vWestIndies,10/09/2021')\n",
    "re = record[:10]\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Female All-Rounder':w_ar,'Ratings':r,'Records':re})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc565cb",
   "metadata": {},
   "source": [
    "QUESTION 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1a1c0bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Headline</th>\n",
       "      <th>Time it got published</th>\n",
       "      <th>Link to the news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jobs and earnings are major themes next week a...</td>\n",
       "      <td>25 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/10/28/jobs-earnings-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here's Americans' net worth at every age—for p...</td>\n",
       "      <td>26 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/10/28/americans-medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Psychologist: Here's my No.1 brain hack for cr...</td>\n",
       "      <td>56 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/10/28/uchicago-psych...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Routine S&amp;P 500 correction or something more s...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/10/28/analyzing-the-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why it's so expensive to be single in the U.S.</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/10/28/why-its-so-exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Use this Google feature to detect and delete y...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/10/28/how-to-delete-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Reddit co-founder: Most successful people shar...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/10/28/reddit-co-foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'Earn Your Leisure' hosts: It may take $10 mil...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/10/28/earn-your-leis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Coke and Pepsi stocks are struggling — but one...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/10/28/coke-and-pepsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Israel-Hamas war is affecting the financial ou...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/10/28/israel-hamas-w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       News Headline Time it got published  \\\n",
       "0  Jobs and earnings are major themes next week a...            25 Min Ago   \n",
       "1  Here's Americans' net worth at every age—for p...            26 Min Ago   \n",
       "2  Psychologist: Here's my No.1 brain hack for cr...            56 Min Ago   \n",
       "3  Routine S&P 500 correction or something more s...            1 Hour Ago   \n",
       "4     Why it's so expensive to be single in the U.S.            1 Hour Ago   \n",
       "5  Use this Google feature to detect and delete y...            1 Hour Ago   \n",
       "6  Reddit co-founder: Most successful people shar...            1 Hour Ago   \n",
       "7  'Earn Your Leisure' hosts: It may take $10 mil...           2 Hours Ago   \n",
       "8  Coke and Pepsi stocks are struggling — but one...           2 Hours Ago   \n",
       "9  Israel-Hamas war is affecting the financial ou...           3 Hours Ago   \n",
       "\n",
       "                                    Link to the news  \n",
       "0  https://www.cnbc.com/2023/10/28/jobs-earnings-...  \n",
       "1  https://www.cnbc.com/2023/10/28/americans-medi...  \n",
       "2  https://www.cnbc.com/2023/10/28/uchicago-psych...  \n",
       "3  https://www.cnbc.com/2023/10/28/analyzing-the-...  \n",
       "4  https://www.cnbc.com/2023/10/28/why-its-so-exp...  \n",
       "5  https://www.cnbc.com/2023/10/28/how-to-delete-...  \n",
       "6  https://www.cnbc.com/2023/10/28/reddit-co-foun...  \n",
       "7  https://www.cnbc.com/2023/10/28/earn-your-leis...  \n",
       "8  https://www.cnbc.com/2023/10/28/coke-and-pepsi...  \n",
       "9  https://www.cnbc.com/2023/10/28/israel-hamas-w...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and\n",
    "make data frame\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link'''\n",
    "\n",
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "soup = BeautifulSoup(page.content)\n",
    "#HEADLINE\n",
    "headline = []\n",
    "for i in soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    headline.append(i.text)\n",
    "h = headline[:10]\n",
    "\n",
    "#TIME\n",
    "time = []\n",
    "for i in soup.find_all('span',class_=\"LatestNews-wrapper\"):\n",
    "    time.append(i.text)\n",
    "t = time[:10]\n",
    "\n",
    "#News Link\n",
    "anchor_tags = soup.find_all('a',class_=\"LatestNews-headline\")\n",
    "urls = [tag.get('href') for tag in anchor_tags if tag.get('href')]\n",
    "urls1 = urls[:10]\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'News Headline':h,'Time it got published':t,'Link to the news':urls1})\n",
    "df\n",
    "\n",
    "#Please run the code again for latest updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ea26d",
   "metadata": {},
   "source": [
    "QUESTION 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "152fc279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Titles</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Margaret A. Boden</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "      <td>January 2022</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "      <td>June 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "      <td>Patrick Lin, Keith Abney, George Bekey</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "      <td>W. Bradley Knox, Alessandro Allievi and 3 more</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "      <td>May 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Paper Titles  \\\n",
       "0                                    Reward is enough   \n",
       "1   Explanation in artificial intelligence: Insigh...   \n",
       "2              Creativity and artificial intelligence   \n",
       "3   Conflict-based search for optimal multi-agent ...   \n",
       "4   Knowledge graphs as tools for explainable mach...   \n",
       "5   Law and logic: A review from an argumentation ...   \n",
       "6   Between MDPs and semi-MDPs: A framework for te...   \n",
       "7   Explaining individual predictions when feature...   \n",
       "8       Multiple object tracking: A literature review   \n",
       "9   A survey of inverse reinforcement learning: Ch...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11  Explainable AI tools for legal reasoning about...   \n",
       "12            Hard choices in artificial intelligence   \n",
       "13  Assessing the communication gap between AI mod...   \n",
       "14  Explaining black-box classifiers using post-ho...   \n",
       "15  The Hanabi challenge: A new frontier for AI re...   \n",
       "16              Wrappers for feature subset selection   \n",
       "17  Artificial cognition for social human–robot in...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  The multifaceted impact of Ada Lovelace in the...   \n",
       "20  Robot ethics: Mapping the issues for a mechani...   \n",
       "21          Reward (Mis)design for autonomous driving   \n",
       "22  Planning and acting in partially observable st...   \n",
       "23  What do we want from Explainable Artificial In...   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021   \n",
       "1                                         Tim Miller    February 2019   \n",
       "2                                  Margaret A. Boden      August 1998   \n",
       "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015   \n",
       "4                     Ilaria Tiddi, Stefan Schlobach     January 2022   \n",
       "5                     Henry Prakken, Giovanni Sartor     October 2015   \n",
       "6    Richard S. Sutton, Doina Precup, Satinder Singh      August 1999   \n",
       "7          Kjersti Aas, Martin Jullum, Anders Løland   September 2021   \n",
       "8                Wenhan Luo, Junliang Xing and 4 more      April 2021   \n",
       "9                      Saurabh Arora, Prashant Doshi      August 2021   \n",
       "10  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021   \n",
       "11  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023   \n",
       "12  Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz    November 2021   \n",
       "13  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023   \n",
       "14  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021   \n",
       "15          Nolan Bard, Jakob N. Foerster and 13 more      March 2020   \n",
       "16                        Ron Kohavi, George H. John    December 1997   \n",
       "17      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017   \n",
       "18   Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz        June 2021   \n",
       "19                            Luigia Carlucci Aiello        June 2016   \n",
       "20            Patrick Lin, Keith Abney, George Bekey       April 2011   \n",
       "21     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023   \n",
       "22  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998   \n",
       "23             Markus Langer, Daniel Oster and 6 more       July 2021   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details and make data frame\n",
    "i) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL'''\n",
    "\n",
    "page1 = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "soup1 = BeautifulSoup(page1.content)\n",
    "\n",
    "#Paper Title\n",
    "paper_title = []\n",
    "for i in soup1.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    paper_title.append(i.text)\n",
    "paper_title\n",
    "\n",
    "#Authors\n",
    "authors = []\n",
    "for i in soup1.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    authors.append(i.text)\n",
    "authors\n",
    "\n",
    "#Published date\n",
    "pub_date = []\n",
    "for i in soup1.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    pub_date.append(i.text)\n",
    "pub_date\n",
    "\n",
    "#Paper URL\n",
    "anchor_tags = soup1.find_all('a',class_=\"sc-5smygv-0 fIXTHm\")\n",
    "urls = [tag.get('href') for tag in anchor_tags if tag.get('href')]\n",
    "urls\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Paper Titles':paper_title,'Authors':authors,'Published Date':pub_date,'Paper URL':urls})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730f5f46",
   "metadata": {},
   "source": [
    "QUESTION 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "34ac1f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>₹ 2,000 for 2 (approx) | Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>₹ 3,000 for 2 (approx) | Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>₹ 2,400 for 2 (approx) | North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>₹ 1,700 for 2 (approx) | North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>₹ 1,800 for 2 (approx) | North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>₹ 1,900 for 2 (approx) | North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>₹ 2,200 for 2 (approx) | North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Barbeque Times</td>\n",
       "      <td>₹ 1,500 for 2 (approx) | North Indian, Contine...</td>\n",
       "      <td>M2K Corporate Park,Sector 51, Gurgaon</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant Name  \\\n",
       "0                   Castle Barbeque   \n",
       "1                        Cafe Knosh   \n",
       "2                       India Grill   \n",
       "3              The Barbeque Company   \n",
       "4                    Delhi Barbeque   \n",
       "5  The Monarch - Bar Be Que Village   \n",
       "6                 Indian Grill Room   \n",
       "7                The Barbeque Times   \n",
       "\n",
       "                                             Cuisine  \\\n",
       "0     ₹ 2,000 for 2 (approx) | Chinese, North Indian   \n",
       "1      ₹ 3,000 for 2 (approx) | Italian, Continental   \n",
       "2     ₹ 2,400 for 2 (approx) | North Indian, Italian   \n",
       "3     ₹ 1,700 for 2 (approx) | North Indian, Chinese   \n",
       "4              ₹ 1,800 for 2 (approx) | North Indian   \n",
       "5              ₹ 1,900 for 2 (approx) | North Indian   \n",
       "6     ₹ 2,200 for 2 (approx) | North Indian, Mughlai   \n",
       "7  ₹ 1,500 for 2 (approx) | North Indian, Contine...   \n",
       "\n",
       "                                            Location Ratings  \\\n",
       "0                     Connaught Place, Central Delhi       4   \n",
       "1  The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "2               Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "3                 Gardens Galleria,Sector 38A, Noida     3.9   \n",
       "4     Taurus Sarovar Portico,Mahipalpur, South Delhi     3.7   \n",
       "5  Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
       "6   Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "7              M2K Corporate Park,Sector 51, Gurgaon     4.1   \n",
       "\n",
       "                                           Image URL  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Write a python program to scrape mentioned details from dineout.co.in and make data frame.\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL'''\n",
    "\n",
    "page2 = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "soup2 = BeautifulSoup(page2.content)\n",
    "\n",
    "#Restaurant name\n",
    "res_name = []\n",
    "for i in soup2.find_all('a',class_=\"restnt-name ellipsis\"):\n",
    "    res_name.append(i.text)\n",
    "res_name\n",
    "\n",
    "#Cuisine\n",
    "cuisine = []\n",
    "for i in soup2.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    cuisine.append(i.text)\n",
    "cuisine\n",
    "\n",
    "#Location\n",
    "location = []\n",
    "for i in soup2.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "location\n",
    "\n",
    "#Ratings\n",
    "ratings = []\n",
    "for i in soup2.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    ratings.append(i.text)\n",
    "ratings\n",
    "\n",
    "#Image URL\n",
    "image_url = []\n",
    "for i in soup2.find_all('img',class_=\"no-img\"):\n",
    "    image_url.append(i['data-src'])\n",
    "image_url\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Restaurant Name':res_name,'Cuisine':cuisine,'Location':location,'Ratings':ratings,'Image URL':image_url})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
